{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import selenium\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import base64\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sleep(base_time=0.5, float_part=1.5):\n",
    "    '''Функция для случайного ожидания'''\n",
    "    \n",
    "    time.sleep(base_time + random.random() * float_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_button(browser, element, by=By.CSS_SELECTOR):\n",
    "    '''Нажимает на элемент и возваращает его'''\n",
    "    \n",
    "    element_present = EC.presence_of_element_located((by, element))\n",
    "    _element = WebDriverWait(browser, 10).until(element_present)\n",
    "    # sleep(1, 2)\n",
    "    browser.execute_script(\"arguments[0].click();\", _element)\n",
    "    sleep()\n",
    "    return _element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_func</th>\n",
       "      <th>lead_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>func</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [parent_func, lead_time]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def timing(func):\n",
    "    \"\"\"\n",
    "    Декоратор, выводящий время, которое заняло\n",
    "    выполнение декорируемой функции.\n",
    "    \"\"\"\n",
    "     \n",
    "    def wrapper(*args, **kwargs):\n",
    "        t = time.time()\n",
    "        res = func(*args, **kwargs)\n",
    "        \n",
    "        # Записываем время выполнения функции в time_df \n",
    "        \n",
    "        # вытаскиваем родительскую функцию с помощью модуля inspect\n",
    "        # можно также это сделать с помощью sys._getframe(1).f_code.co_name\n",
    "        # но этот метод вообще начинается с нижнего подчеркивания\n",
    "        # хз все кривое)) нужна ли родительская функция?\n",
    "        time_df.loc[func.__name__] = [inspect.stack()[1].function, time.time() - t]\n",
    "        return res\n",
    "    return wrapper\n",
    "\n",
    "# Создаем DataFrame для записи времени прохождения каждой функции\n",
    "time_df = pd.DataFrame(columns=['parent_func', 'lead_time'])\n",
    "time_df.index.name = 'func'\n",
    "time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def receive_time_df(my_soup, feat_list=['minute', 'data_type'], mode='match-centre', *args):\n",
    "    \n",
    "    '''Функция находит все элементы в общей каше данных, которые отвечают сходятся с *args,\n",
    "       затем ищет среди них значения атрибутов из списка(feat_list) доставая их описание\n",
    "       из внутреннего списка attr_dict. Поэтому каждый элемент в feat_list должен быть\n",
    "       представлен в attr_dict'''\n",
    "    \n",
    "    def _inner_func(inc, feature_attr):\n",
    "        \n",
    "        '''Внутренняя функция ищет заданный атрибут(feature_attr[name]) в данном элементе(inc)\n",
    "           и возвращает его значение. \n",
    "           Если значения сравнения с пустотой(feature_attr[empty_comparison]) равно True,\n",
    "           то функция просто проверяет, есть ли заданный атрибут(feature_attr[name]) в данном элементе(inc)\n",
    "           и возвращает булево значение наличия'''\n",
    "        \n",
    "        if feature_attr['empty_comparison']:\n",
    "            return inc.get(feature_attr['name']) == ''\n",
    "        else:\n",
    "            return inc.get(feature_attr['name']) \n",
    "\n",
    "    attr_dict = {'minute':        {'name': 'data-minute', 'empty_comparison': False},\n",
    "                 'second':        {'name': 'data-second', 'empty_comparison': False},\n",
    "                 'team_id':       {'name': 'data-team-id', 'empty_comparison': False},\n",
    "                 'player_id':     {'name': 'data-player-id', 'empty_comparison': False},\n",
    "                 'assist':        {'name': 'data-event-satisfier-assist', 'empty_comparison': True},\n",
    "                 'data_type':     {'name': 'data-type', 'empty_comparison': False},\n",
    "                 'yellow_card':   {'name': 'data-event-satisfier-yellowcard', 'empty_comparison': True},\n",
    "                 'second_yellow': {'name': 'data-event-satisfier-secondyellow', 'empty_comparison': True},\n",
    "                 'red_card':      {'name': 'data-event-satisfier-redcard', 'empty_comparison': True},\n",
    "                 'card_type':     {'name': 'data-card-type', 'empty_comparison': False},\n",
    "                 'penalty':       {'name': 'data-event-satisfier-penaltyscored', 'empty_comparison': True},\n",
    "                 'penalty_miss':  {'name': 'data-event-satisfier-penaltymissed', 'empty_comparison': True},\n",
    "                 'goal_own':      {'name': 'data-event-satisfier-goalown', 'empty_comparison': True},\n",
    "                 'error_lead':    {'name': 'data-event-satisfier-errorleadstogoal', 'empty_comparison': True},\n",
    "                 'shots_on_post': {'name': 'data-event-satisfier-shotonpost', 'empty_comparison': True},\n",
    "                 'clear_line':    {'name': 'data-event-satisfier-clearanceofftheline', 'empty_comparison': True},\n",
    "                 'tacklelastman': {'name': 'data-event-satisfier-tacklelastman', 'empty_comparison': True}}\n",
    "    \n",
    "    # Достаем все элементы подходящие под заданный поиск\n",
    "    tab = my_soup.findAll(*args)\n",
    "    # Если разбираем timeline для chalkboard, то дополнительно раскрываем внутренние списки,\n",
    "    # так как тут ячейки ищем по родительскому тегу\n",
    "    # (чтобы легко можно было разделить на первый и второй тайм, добавляя on-right)\n",
    "    if mode == 'chalkboard':\n",
    "        tab = [y for i in tab for y in i.findChildren(recursive=False)]\n",
    "    \n",
    "    # Для каждого инцидента достаем все атрибуты из feat_list и складываем в словарь\n",
    "    inc_list = []\n",
    "    for incident in tab:\n",
    "        inc_dict = {}\n",
    "        for feature in feat_list:\n",
    "            if feature == 'text':\n",
    "                inc_dict[feature] = incident.findAll(text=True)[-1]  # пока текст по кривому достаю\n",
    "            else:\n",
    "                inc_dict[feature] = _inner_func(incident, attr_dict[feature])\n",
    "        inc_list.append(inc_dict)\n",
    "    \n",
    "    return pd.DataFrame(inc_list)\n",
    "\n",
    "# live_inc_list = ['minute', 'second', 'team_id', 'player_id', 'data_type']\n",
    "# receive_time_df(live_inc, live_inc_list, *('div', {'class': 'incident-icon'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def timeline_exec(my_soup, attr_list, name, cls, mode='match-centre'):\n",
    "    \"\"\"Функция выделяет и объединяет полосы моментов в один DataFrame\"\"\"\n",
    "    \n",
    "    timeline_df = pd.DataFrame(columns=['minute', 'second']) #.set_index(['minute', 'second'])\n",
    "    # Выбираем полосу моментов по каждой из сторон\n",
    "    for side in ['home', 'away']:\n",
    "        mc_timeline = my_soup.find('div', {'id': mode + '-timeline'}).find('div', {'class': 'timeline-events',\n",
    "                                                                                        'data-field': side})\n",
    "        # Выгружаем первый тайм\n",
    "        first_time = receive_time_df(mc_timeline, attr_list, mode, name, cls)\n",
    "        first_time['half'] = 1\n",
    "        \n",
    "        # добавляем в элементы поиска для второго тайма on-right\n",
    "        cls2 = {'class': value + 'on-right' for key, value in cls.items()}\n",
    "                    \n",
    "        # Выгружаем второй тайм\n",
    "        second_time = receive_time_df(mc_timeline, attr_list, mode, name, cls2)\n",
    "        second_time['half'] = 2\n",
    "        \n",
    "        # Объединяем оба тайма в один DataFrame\n",
    "        timeline_df_side = pd.concat([first_time, second_time], ignore_index=True, sort=False)\n",
    "        # timeline_df_side = timeline_df_side.set_index(['minute', 'second'])\n",
    "        timeline_df_side['side'] = side\n",
    "        \n",
    "        # Добавляем к общему DataFrame\n",
    "        timeline_df = pd.concat([timeline_df, timeline_df_side], sort=False)\n",
    "    return timeline_df.set_index(['minute', 'second'])\n",
    "    \n",
    "\n",
    "# timeline_attr_list = ['minute', 'second', 'team_id', 'player_id', 'assist', 'data_type', 'yellow_card',\n",
    "#                       'second_yellow', 'red_card', 'card_type', 'penalty', 'penalty_miss', 'goal_own',\n",
    "#                       'error_lead', 'shots_on_post', 'clear_line', 'tacklelastman', 'text']\n",
    "\n",
    "# timeline_df = timeline_exec(soup, timeline_attr_list, 'div', {'class': 'timeline-event incident-icon '})\n",
    "# timeline_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для чтения состава и его атрибутов\n",
    "def receive_stad(my_soup, category):\n",
    "    stad_data = my_soup.find('div', {'id': 'stadium'})\n",
    "    player_list = []\n",
    "    \n",
    "    for side in ('home', 'away'):\n",
    "        # Читаем данные основы\n",
    "        pitch_data = stad_data.find('div', {'class': 'pitch-field', 'data-field': side})\n",
    "        team_id = pitch_data['data-team-id']\n",
    "        \n",
    "        # для каждого подкласса в основе\n",
    "        for child in pitch_data.children:\n",
    "            player_dict = {}\n",
    "            player_dict['player_id'] = child['data-player-id']\n",
    "            \n",
    "            # Если рейтинг(первая) то читаем все дополнительные показатели игрок матча, в основе ли и т.д.\n",
    "            if category == 'rating':\n",
    "                player_dict['star'] = child['class'][-1] == 'is-man-of-the-match'\n",
    "                player_dict['team_id'] = team_id\n",
    "                player_dict['cast'] = 'first'               # для основы first\n",
    "                player_dict['side'] = side\n",
    "            \n",
    "            # считываем название категории\n",
    "            player_dict[category] = child.find('div', {'class': 'player-stat'}).find(text=True)\n",
    "            \n",
    "            player_list.append(player_dict)\n",
    "        \n",
    "        # Читаем данные скамейки\n",
    "        bench = stad_data.find('div', {'class': 'substitutes', 'data-field': side})\n",
    "        \n",
    "        # для каждого покласса скамейки\n",
    "        for child in bench.children:\n",
    "            player_dict = {}\n",
    "            player_dict['player_id'] = child['data-player-id']\n",
    "            \n",
    "            # только если категория рейтинг(первая) считываем остальные данные по игрокам\n",
    "            if category == 'rating':\n",
    "                player_dict['star'] = child['class'][-1] == 'is-man-of-the-match'\n",
    "                player_dict['team_id'] = team_id\n",
    "                player_dict['cast'] = 'sub'                     # для скамейки sub\n",
    "                player_dict['side'] = side\n",
    "            \n",
    "            player_dict[category] = child.find('div', {'class': 'player-stat'}).find(text=True)\n",
    "            \n",
    "            player_list.append(player_dict)\n",
    "    \n",
    "    return pd.DataFrame(player_list).set_index(['player_id'])        \n",
    "\n",
    "#receive_stad(soup, 'rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A4</td>\n",
       "      <td>B4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A5</td>\n",
       "      <td>B5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B\n",
       "4  A4  B4\n",
       "5  A5  B5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Функция для быстрого создания примеров\n",
    "def make_df(cols, ind):\n",
    "    data = {c: [str(c) + str(i) for i in ind] for c in cols}\n",
    "    return pd.DataFrame(data, ind)\n",
    "\n",
    "AB = make_df('AB', range(4, 6))\n",
    "print(np.all(AB.iloc[:, -1].values == make_df('B', range(4, 6)).iloc[:, -1].values))\n",
    "AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_main_stat(_soup, tableName=[]):\n",
    "    '''Функция достает общую статистику по командам за матч'''\n",
    "    \n",
    "    main_stat_list = []\n",
    "    for side in ('home', 'away'):\n",
    "        team_info = _soup.find('div', {'class': 'match-centre-header-team', 'data-field': side})\n",
    "        team_info_dict = {} \n",
    "        team_info_dict['manager_name'] = team_info.find('span', {'class': 'manager-name'}).text\n",
    "        team_info_dict['team_name'] = team_info.find('a', {'class': 'team-name'}).text\n",
    "        team_info_dict['formation'] = team_info.find('div', {'class': 'formation'}).text\n",
    "        # Рейтинг достаем отдельно от остальной статистики\n",
    "        team_info_dict['rating'] = team_info.find('div', {'class': 'team-rating'}).text\n",
    "\n",
    "        for main_name, sub in tableName.items():\n",
    "            \n",
    "            stat_element = _soup.find('li', {'class': 'match-centre-stat has-stats', 'data-for': main_name})\n",
    "          \n",
    "            team_info_dict[main_name] = stat_element.find('span', {'data-field': side})['data-value']\n",
    "            for sub_name in sub:\n",
    "                sub_element = _soup.find('li', {'class': 'match-centre-stat match-centre-sub-stat', 'data-for': sub_name})\n",
    "                team_info_dict[sub_name] = sub_element.find('span', {'data-field': side})['data-value']\n",
    "                \n",
    "        main_stat_list.append(team_info_dict)\n",
    "        \n",
    "    main_stat_df = pd.DataFrame(main_stat_list, index=('home', 'away')).T\n",
    "    return main_stat_df\n",
    "\n",
    "# get_main_stat(soup, tableName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_info(_soup):\n",
    "    '''Достает общую информацию о матче(погода, посещаемость, судья, стадион)'''\n",
    "    match_info = _soup.find('div', {'class': 'match-info'})\n",
    "    match_info_dict = {}\n",
    "    match_info_dict['venue'] = match_info.find('span', {'class': 'venue'})['data-core-value']\n",
    "    match_info_dict['attendance'] = match_info.find('span', {'class': 'attendance'})['data-core-value']\n",
    "    match_info_dict['weather_name'] = match_info.find('span', {'class': 'weather'})['data-value']\n",
    "    match_info_dict['weather_code'] = match_info.find('span', {'class': 'weather'})['data-core-value']\n",
    "    match_info_dict['referee'] = match_info.find('span', {'class': 'referee'})['title']\n",
    "\n",
    "    return pd.Series(match_info_dict)\n",
    "\n",
    "# get_match_info(soup)\n",
    "# soup.findAll('div', {'class': 'match-info'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(browser, css_element, mode='main'):\n",
    "    \"\"\"Функция находит и выбирает заданный в css_element элемент,\n",
    "       а также раскрывает кнопку more в элементе если стоит режим main.\n",
    "       И возвращает контент страницы после нажатия\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # получаем назад элемент чтобы потом внетри него нажать кнопку more если main\n",
    "        element = click_button(browser, css_element)\n",
    "        \n",
    "        if mode == 'main':\n",
    "            more_button_css = 'div[class*=\"toggle-stat-details iconize iconize-icon-right ui-state-transparent-default\"]'\n",
    "            button = element.find_element(By.CSS_SELECTOR, more_button_css)\n",
    "            button.click()\n",
    "    except:\n",
    "        print(\"Problem with \", css_element)\n",
    "        sleep()\n",
    "\n",
    "    # Загружаем данные страницы\n",
    "    content = browser.page_source\n",
    "    soup = BeautifulSoup(''.join(content), 'lxml')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_aditional_cat(player_stats, browser, tableName, main_stat_df):\n",
    "    '''Добавляет в player_stats все данные по категориям из tableName'''\n",
    "    \n",
    "    def _add_cat(browser, stat_df, cat_name, css_elem, main_stat_df, mode='main'):\n",
    "        '''Внутренняя функция достает с помощью get_content данные по игрокам в категории\n",
    "           и проверяет ее на ошибку сравнивая с предыдущей. И заносит в общий\n",
    "           DataFrame по игрокам'''\n",
    "\n",
    "        main_soup = get_content(browser, css_elem, mode)\n",
    "        cat_df = receive_stad(main_soup, cat_name)\n",
    "        \n",
    "        # достаем данные по предыдущей категории для сравнения с текущей\n",
    "        previous_stat = stat_df.iloc[:, -1].values\n",
    "\n",
    "        # Если собранные данные по текущей категории по игрокам полностью совпадает с предыдущей \n",
    "        # и сумма из таблицы с общими данными по данной категории равна нулю \n",
    "        # и тогда данные в виджете не обновляются. Поэтому просто проставляем пустые значения в таких случаях.\n",
    "        if np.all(np.all(previous_stat == cat_df.iloc[:, -1].values) and main_stat_df.loc[[cat_name]].astype('float').sum(1) == 0):\n",
    "            stat_df[cat_name] = None\n",
    "        else:\n",
    "            stat_df = stat_df.join(cat_df)\n",
    "\n",
    "        return stat_df\n",
    "    \n",
    "    # для каждой основной категории и списка дополнительных\n",
    "    for main_name, sub in tableName.items():\n",
    "\n",
    "        main_css = \"li[class*='match-centre-stat  has-stats'][data-for='\" + main_name + \"']\"\n",
    "        # добавляешь категорию в общий df\n",
    "        player_stats = _add_cat(browser, player_stats, main_name, main_css, main_stat_df)\n",
    "        \n",
    "        # для каждой дополнительной категории\n",
    "        for sub_name in sub:\n",
    "            sub_css = \"li[class*='match-centre-stat match-centre-sub-stat'][data-for='\" + sub_name + \"']\"\n",
    "            # добавляем категорию в общий df\n",
    "            player_stats = _add_cat(browser, player_stats, sub_name, sub_css, main_stat_df, 'sub')\n",
    "            \n",
    "    return player_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing\n",
    "def get_match_center_data(browser, timeline_attr_list, match_center_cat_table):\n",
    "    # Загружаем все данные с изначальной страницы\n",
    "\n",
    "    content = browser.page_source\n",
    "    soup = BeautifulSoup(''.join(content), 'lxml')\n",
    "\n",
    "    # Достаем данные по погоде, полю и рефери\n",
    "    match_info = get_match_info(soup)\n",
    "\n",
    "    # можно еще добавить разбор данных из верхнего Timeline\n",
    "    # (timeline_exec изначально ее разбирал и в нем есть такой режим), правда в нижнем timeline просто больше данных:))\n",
    "\n",
    "    # Получаем DataFrame с основными моментами за игру\n",
    "    timeline_mc_df = timeline_exec(soup, timeline_attr_list, 'div', {'class': 'timeline-event incident-icon '})\n",
    "\n",
    "    # Получаем изначальную статистику по игрокам(рейтинг)\n",
    "    player_stats = receive_stad(soup, 'rating')\n",
    "\n",
    "    # Достаем остальную информацию по игрокам\n",
    "\n",
    "    \n",
    "\n",
    "    # С помощью функции get_main_stat достаем общую за матч статистику по командам\n",
    "    main_stat_df = get_main_stat(soup, match_center_cat_table)\n",
    "\n",
    "    # достаем дополнительную статистику по игрокам в категориях из таблицы tableName\n",
    "    # и добавляем ее в player_stats\n",
    "\n",
    "    player_stats = add_aditional_cat(player_stats, browser, match_center_cat_table, main_stat_df)\n",
    "    \n",
    "    return match_info, timeline_mc_df, main_stat_df, player_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing\n",
    "def get_chalkboard_data(browser, cat_table, timeline_attr_list, chalk_data_df=None):\n",
    "    '''Достаем и нажимаем(click_button) на каждую категорию из cat_table,\n",
    "       далее с помощью внутренней функции добавляем данные по каждой из них в общий DataFrame'''\n",
    "    \n",
    "    def _add_category_data(browser, chalk_data_df, timeline_attr_list, category, subcategory=None):\n",
    "        '''Достаем из Timeline данные по категории с помощью timeline_exec,\n",
    "           выбирая в данных атрибуты из timeline_attr_list\n",
    "           если это первый вызов функции общего chalk_data_df еще нет,\n",
    "           то он будет просто возвращен получившийся из timeline_exec DataFrame,\n",
    "           в другом случае данные прибавяться к уже имеющемся в chalk_data_df'''\n",
    "        \n",
    "        content = browser.page_source\n",
    "        _soup = BeautifulSoup(''.join(content), 'lxml')\n",
    "        \n",
    "        # грузим данные по категории\n",
    "        cat_df = timeline_exec(_soup, timeline_attr_list,\n",
    "                               'div', {'class': 'chalkboard-timeline-events '},\n",
    "                               mode='chalkboard')\n",
    "        cat_df['category'] = category\n",
    "        cat_df['subcat'] = subcategory\n",
    "        # Если первый случай то создаем новый df\n",
    "        if chalk_data_df is None:\n",
    "            chalk_data_df = cat_df\n",
    "        else:\n",
    "            chalk_data_df = pd.concat([chalk_data_df, cat_df], sort=False)\n",
    "            \n",
    "        return chalk_data_df\n",
    "\n",
    "    def is_category_empty(browser, xpath_element, mode='main'):\n",
    "        '''Проверка на наличие данных по данной категории, если данных нет то след. итерация'''\n",
    "        # если основная категория\n",
    "        if mode == 'main':\n",
    "            test_xpath_element = xpath_element + '/../..'\n",
    "        # если дополнительная\n",
    "        elif mode == 'sub':\n",
    "            test_xpath_element = xpath_element + '/..'\n",
    "        elem = browser.find_element_by_xpath(test_xpath_element)\n",
    "        # возвращаем булево значение пустая ли улика\n",
    "        return elem.get_attribute('data-sum') == '0'\n",
    "        \n",
    "    # Переходим в Chalkboard\n",
    "    css_element = 'a[href=\"#chalkboard\"]'\n",
    "    click_button(browser, css_element)\n",
    "    sleep(1, 2)\n",
    "    \n",
    "    # для основных атрибутов и списков дополнительных\n",
    "    for main_attr, sub in cat_table.items():\n",
    "        \n",
    "        xpath_element = '//li[@class=\"filterz-option\"]/a/h4[text()=\"' + main_attr + '\"]'\n",
    "        \n",
    "        # проверка пустой категории\n",
    "        if is_category_empty(browser, xpath_element, 'main'):\n",
    "            continue\n",
    "        # нажимаем на категорию\n",
    "        click_button(browser, xpath_element, By.XPATH)\n",
    "        \n",
    "        # добавляем данные по категории в df\n",
    "        chalk_data_df = _add_category_data(browser, chalk_data_df, timeline_attr_list, main_attr)\n",
    "        \n",
    "        # для каждой дополнительной категории\n",
    "        for sub_attr in sub:\n",
    "            \n",
    "            xpath_element = '//div[@class=\"filterz-filter\"]/label[text()=\"' + sub_attr + '\"]'\n",
    "            # Проверка пустой категории\n",
    "            if is_category_empty(browser, xpath_element, 'sub'):\n",
    "                continue\n",
    "            # нажимаем на категорию\n",
    "            click_button(browser, xpath_element, By.XPATH)\n",
    "            \n",
    "            chalk_data_df = _add_category_data(browser, chalk_data_df, timeline_attr_list, main_attr, sub_attr)\n",
    "            \n",
    "            # Повторно нажимаем кнопку, чтобы выключить выделение\n",
    "            # чтобы получать полную статистику, если еще есть дополнительные категории\n",
    "            xpath_element = '//div[@class=\"filterz-filter selected\"]/label[text()=\"' + sub_attr + '\"]'\n",
    "            click_button(browser, xpath_element, By.XPATH)\n",
    "            \n",
    "    return chalk_data_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_summary(soup):\n",
    "    '''Функция достает данные из Match Summary в Match report укладывая их в словарь,\n",
    "       затем с помощью функции create_df создает общий DataFrame'''\n",
    "    def get_match_summary_data(soup):\n",
    "        \n",
    "        table_match_summary = soup.find('table', {'class': 'matchstory'})\n",
    "        char_list = {i: {'Strengths': [], 'Weaknesses': [], 'Styles': []} for i in ['home', 'away']}\n",
    "        for line in table_match_summary.findAll('tr'):\n",
    "            if line['class'] == ['teamheader']:\n",
    "                char_list['home']['team'], char_list['away']['team'] = [i for i in line.findAll(text=True) if i != '\\n']\n",
    "            elif line['class'] == ['matchstory-typeheader']:\n",
    "                typeheader = [i for i in line.findAll(text=True) if i != '\\n'][0]\n",
    "                if typeheader in ['Strengths', 'Weaknesses', 'Styles']:\n",
    "                    home_list = char_list['home'][typeheader]\n",
    "                    away_list = char_list['away'][typeheader]\n",
    "                else:\n",
    "                    raise BaseException\n",
    "            elif line['class'] == ['matchstory-row']:\n",
    "                td_list = line.findAll('td')\n",
    "                td_line = []\n",
    "                for td in td_list:\n",
    "                    span = td.find('span')\n",
    "                    if span is not None:\n",
    "                        td_line.append(span.find(text=True))\n",
    "                    else: \n",
    "                        td_line.append(None)\n",
    "\n",
    "                home_list.append(td_line[0])\n",
    "                away_list.append(td_line[1])\n",
    "        return char_list\n",
    "\n",
    "    \n",
    "    def create_df(char_list):\n",
    "        def create_internal_df(key, llist, team, side):\n",
    "            df = pd.DataFrame(llist, columns=['Char']).dropna()\n",
    "            df['+/-'] = key\n",
    "            df['Team'] = team\n",
    "            df['Side'] = side\n",
    "\n",
    "            return df\n",
    "        return_list = []\n",
    "        for side in char_list:\n",
    "            side_df_list = []\n",
    "            side_list = char_list[side]\n",
    "            team = side_list['team']\n",
    "\n",
    "            for key in [i for i in side_list if i != 'team']:\n",
    "                internal_df = create_internal_df(key, side_list[key], team, side)\n",
    "                side_df_list.append(internal_df)\n",
    "\n",
    "            side_df = pd.concat(side_df_list, ignore_index=True)\n",
    "            return_list.append(side_df)\n",
    "\n",
    "        char_df = pd.concat(return_list, ignore_index=True)\n",
    "        return char_df\n",
    "    \n",
    "    data_list = get_match_summary_data(soup)\n",
    "    match_summary_df = create_df(data_list)\n",
    "    \n",
    "    return match_summary_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing\n",
    "def get_situational_report_data(browser, css_list_sit_but, div_id_sit_dict, xpath_attempt_type_list):\n",
    "    '''Функция с помощью внутренней функции get_label_content нажимает на все кнопки из css_list_sit_but\n",
    "       (после активации каждого меню все данные есть), затем из общего супа достает данные по каждому\n",
    "       label-значению из div_id_dict\n",
    "       Потом с помощью функции get_goal_attempt_types достаем дополнительный параметр - голы по типу атаки.\n",
    "       Приходится доставать их дополнительно, так как необходимо нажимать на кнопки внутреннего меню situational report\n",
    "       Затем объединяем все это в общий DataFrame и возвращаем его.'''\n",
    "    \n",
    "    def get_label_content(browser, div_id_sit_dict, css_list):\n",
    "        \n",
    "        def get_one_label_content(soup, div_id, label):\n",
    "            '''1) Достаем текстовые данные, начиная со второго элемента,\n",
    "               2) Из сгруппированных по тройкам данных достаем статистику \n",
    "                  по домашней, гостевой команде и названию показателя'''\n",
    "            data_list = soup.find('div', {'id': div_id}).findAll(text=True)[1:]\n",
    "\n",
    "            def grouped(iterable, n):\n",
    "                '''Группирует словарь по кортежам с n-кол-вом объектов словаря'''\n",
    "                \"s -> (s0,s1,s2,...sn-1), (sn,sn+1,sn+2,...s2n-1), (s2n,s2n+1,s2n+2,...s3n-1), ...\"\n",
    "                return zip(*[iter(iterable)]*n)\n",
    "            index, data = [], []\n",
    "            \n",
    "            # немного топорная группировка, но работает)\n",
    "            for home, title, away in grouped(data_list, 3):\n",
    "                label_dict = {}\n",
    "                label_dict['home'] = home\n",
    "                label_dict['away'] = away\n",
    "                data.append(label_dict)\n",
    "                # Приьавояем label, чтобы избежать путаницы с названиями внутри общего DataFrame\n",
    "                index.append(title + ' ' + label)\n",
    "            return pd.DataFrame(data, index)\n",
    "        \n",
    "        # Нажимаем на все кнопки\n",
    "        for css in css_list:\n",
    "            click_button(browser, css)\n",
    "\n",
    "        content = browser.page_source\n",
    "        soup = BeautifulSoup(''.join(content), 'lxml')\n",
    "\n",
    "        label_df_list = []\n",
    "        \n",
    "        # div_id_dict состоит из label-ключа и словаря с id-значениями таблиц с данными\n",
    "        for label, div_id_list in div_id_sit_dict.items():\n",
    "            for div_id in div_id_list:\n",
    "                # из каждой таблицы достаем данные\n",
    "                label_df = get_one_label_content(soup, div_id, label)\n",
    "                # Добавляя в общий список\n",
    "                label_df_list.append(label_df)\n",
    "\n",
    "        main_df = pd.concat(label_df_list)\n",
    "        \n",
    "        # Возварщаем суп для последующего использования\n",
    "        return main_df, soup  \n",
    "        \n",
    "    def get_goal_attempt_types(browser, attempt_types):\n",
    "        \n",
    "        attempt_list = []\n",
    "    \n",
    "        for attempt in attempt_types:\n",
    "            # Нажимаем на каждую кнопку из списка attempt_types внутреннего меню situational Report\n",
    "            # в категории attempt types\n",
    "            search_pattern = '//div[@id=\"live-goals-content-comparision\"]/div/div/span[text()=\"' + attempt + '\"]'\n",
    "            click_button(browser, search_pattern, By.XPATH)\n",
    "\n",
    "            goal_dict = {}\n",
    "            # span - номер элемента в списке для задания шаблона поиска(Нумерация в списке начинается с 1)\n",
    "            for side, span in (('home', '2'), ('away', '4')):\n",
    "                xpath_pattern_goal_get = '//div[@id=\"live-goals-info\"]/div/div[3]/span/span[' + span + ']'\n",
    "                text = browser.find_element_by_xpath(xpath_pattern_goal_get).text\n",
    "                goal_dict[side] = text\n",
    "            attempt_list.append(goal_dict)\n",
    "        # Прибавляем goal чтобы потом не было путаницы с названиями внутри DataFrame\n",
    "        goal_name = ['Goal(' + i + ')' for i in xpath_attempt_type_list]\n",
    "        return pd.DataFrame(attempt_list, goal_name)\n",
    "    \n",
    "    label_df, soup = get_label_content(browser, div_id_sit_dict, css_list_sit_but)\n",
    "\n",
    "    goal_type_df = get_goal_attempt_types(browser, xpath_attempt_type_list)\n",
    "\n",
    "    label_df = pd.concat([goal_type_df, label_df])\n",
    "    \n",
    "    return label_df, soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_canvas_list(browser, match_id, png_list, png_dir):\n",
    "    '''\n",
    "    Загружает canvas-фото из positional report страницы match_report\n",
    "    по указанному в png_dir пути. \n",
    "    png_list состоит из словарей с id для поиска фотографий\n",
    "    \n",
    "    Название каждой фотографии строится по следующему шаблону: \n",
    "    match_id-png_list[0, 1, ...][stat_name]-png_list[0, 1, ...][side_name]\n",
    "    '''\n",
    "    \n",
    "    def get_canvas_img(browser, match_id, stat_id, canvas_id, png_dir, stat_name, side_name):\n",
    "        '''\n",
    "        Загрузка одной фотграфии'''\n",
    "        \n",
    "        # Создаем путь прибавляя png_dir к текущему рабочему каталогу\n",
    "        png_dir = os.path.join(os.getcwd(), png_dir)\n",
    "        \n",
    "        # Если не существует путь мы его создаем\n",
    "        if not os.path.exists(png_dir):\n",
    "            os.makedirs(png_dir)\n",
    "        \n",
    "        css_selector = '#{} #{}'.format(stat_id, canvas_id)\n",
    "        \n",
    "        img_name = '{}-{}-{}.png'.format(match_id, stat_name, side_name)   \n",
    "        \n",
    "        canvas = browser.find_element_by_css_selector(css_selector)\n",
    "\n",
    "        # get the canvas as a PNG base64 string\n",
    "        canvas_base64 = browser.execute_script(\"return arguments[0].toDataURL('image/png').substring(21);\", canvas)\n",
    "\n",
    "        # decode\n",
    "        canvas_png = base64.b64decode(canvas_base64)\n",
    "\n",
    "        # save to a file\n",
    "        with open(os.path.join(png_dir, img_name), 'wb') as f:\n",
    "            f.write(canvas_png)\n",
    "    \n",
    "    # Для каждой картинки в png_list\n",
    "    for pic in png_list:\n",
    "        # Нажимаем на кнопку если это не изначальная картинка\n",
    "        if pic['stat_id'] != 'live-touch-channels':\n",
    "            css_selector = 'a[href=\"#{}\"]'.format(pic['stat_id'])\n",
    "            click_button(browser, css_selector)\n",
    "        # если для домашних и гостевых данных единый рисунок, грузим один   \n",
    "        if pic['home'] == pic['away']:\n",
    "            get_canvas_img(browser, match_id, pic['stat_id'], pic['home'], png_dir,\n",
    "                           pic['stat_name'], 'home_away')\n",
    "        # в обычных случаях грузим две фотографии\n",
    "        else:\n",
    "            for side in ['home', 'away']:\n",
    "                get_canvas_img(browser, match_id, pic['stat_id'], pic[side], png_dir,\n",
    "                               pic['stat_name'], side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing\n",
    "def get_match_report_data(browser, css_list_sit_but, div_id_dict, xpath_attempt_type_list,\n",
    "                          png_id_list, match_id, png_dir):\n",
    "    '''\n",
    "    Переключается во вкладку match_report\n",
    "    и загружает данные из match summary, situational report и фото из positional report\n",
    "    '''\n",
    "    \n",
    "    xpath_match_report = '//a[text()=\"Match Report\"]'\n",
    "    click_button(browser, xpath_match_report, By.XPATH)\n",
    "    sleep()\n",
    "    \n",
    "    # Достаем данные из situational report\n",
    "    # match_report_soup для последующей выгрузки match_summary-данных\n",
    "    sit_report_data, match_report_soup = get_situational_report_data(browser, css_list_sit_but,\n",
    "                                                                     div_id_dict, xpath_attempt_type_list)\n",
    "    \n",
    "    # Достаем match_summary-данные\n",
    "    match_summary = get_match_summary(match_report_soup)\n",
    "    \n",
    "    # загружаем фотки\n",
    "    load_canvas_list(browser, match_id, png_id_list, png_dir)\n",
    "    \n",
    "    return sit_report_data, match_summary       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_char_data(h2h_soup):\n",
    "    '''Достаем данные из Team Characteristic'''\n",
    "    # Выделяем суп с данными\n",
    "    team_char_soup = h2h_soup.find('div', {'class': 'character-card for-comparision'})\n",
    "    # Словарь для создания DataFrame\n",
    "    data_list = []\n",
    "    # для каждой группы \n",
    "    for char in ['strengths', 'weaknesses', 'style']:\n",
    "        # Выделяем суп для каждой характеристики\n",
    "        char_soup = team_char_soup.find('div', {'class': char})\n",
    "        for side in ['home', 'away']:\n",
    "            # Выделяем суп для каждой стороны\n",
    "            side_soup = char_soup.find('div', {'class': side})\n",
    "            \n",
    "            # У style другое внутреннее устройство\n",
    "            if char != 'style':\n",
    "                storage_mode = 'tr'\n",
    "            else:\n",
    "                storage_mode = 'li'\n",
    "                \n",
    "            feature_list = side_soup.findAll(storage_mode)\n",
    "            \n",
    "            for feature_soup in feature_list:\n",
    "                # У style другое внутреннее устройство\n",
    "                if char != 'style':\n",
    "                    # print(feature_soup)\n",
    "                    feat_text_soup, feat_quality_soup = feature_soup.findAll('td')\n",
    "                else: \n",
    "                    feat_text_soup, feat_quality_soup = feature_soup, None\n",
    "                \n",
    "                # направаление атака/оборона\n",
    "                feature_attr = feat_text_soup.find('span')['title']\n",
    "                # достаем свойство команды текстом и обрезаем пробелы в начале и конце\n",
    "                feature_text = feat_text_soup.text.strip()\n",
    "                # качество свойства достается текстом, но в style их нет для этого улсовие\n",
    "                feature_qual = feat_quality_soup.text.strip() if feat_quality_soup is not None else None\n",
    "                \n",
    "                # создаем словарь для каждого свойства\n",
    "                d_dict = {}\n",
    "                d_dict['characteristic'] = char\n",
    "                d_dict['side'] = side\n",
    "                d_dict['attr_dir'] = feature_attr\n",
    "                d_dict['feature'] = feature_text\n",
    "                d_dict['quality'] = feature_qual\n",
    "                \n",
    "                # и добавляем словарь в список для создания DataFrame\n",
    "                data_list.append(d_dict)\n",
    "\n",
    "    return pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forecast(h2h_soup):\n",
    "    '''Функция достает данные из xml супа по предсказаниям и укладывает их в DataFrame'''\n",
    "    \n",
    "    # Выделяем суп с предсказаниями\n",
    "    forecast_soup = h2h_soup.find('div', {'id': 'match-forecast'})\n",
    "\n",
    "    # создаем список строк таблицы\n",
    "    forecast_table = forecast_soup.findAll('tr')\n",
    "    data_list = []\n",
    "    # для каждой строки таблицы\n",
    "    for tr in forecast_table:\n",
    "        # находим все ячейки в этой строке\n",
    "        td_list = tr.findAll('td')\n",
    "        \n",
    "        # Первая ячейка состоит из Названия команды и текста предсказания\n",
    "        forecast = td_list[0].findAll(text=True)\n",
    "        fcast = {}\n",
    "        \n",
    "        fcast['team'] = forecast[0]\n",
    "        fcast['forecast'] = forecast[1]\n",
    "        # Во второй ячейке вероятность текстом\n",
    "        fcast['probability'] = td_list[1].text\n",
    "\n",
    "        data_list.append(fcast)\n",
    "\n",
    "    return pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing\n",
    "def get_h2h_data(browser, xpath_h2h):\n",
    "    click_button(browser, xpath_head_2_head, By.XPATH)\n",
    "    sleep()\n",
    "\n",
    "    content = browser.page_source\n",
    "    h2h_soup = BeautifulSoup(''.join(content), 'lxml')\n",
    "    \n",
    "    # Получаем данные о характеристиках команды\n",
    "    h2h_char_df = get_char_data(h2h_soup)\n",
    "    # Получаем предсказание whoscored(или Opta хз)\n",
    "    h2h_forecast_df = get_forecast(h2h_soup)\n",
    "    \n",
    "    return h2h_char_df, h2h_forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Match center\n",
    "# match_info      общая информация по матчу (погода, посещаемость, стадион, рефери)\n",
    "# timeline_mc_df  основные моменты с нижнего timeline  - по минутам изначальные формации, карточки, голы, замены.\n",
    "# main_stat_df    общая статистика за матч по командам - общая по матчу\n",
    "# player_stats    статистика за матч по игрокам        - общая по матчу, дан только id игроков\n",
    "\n",
    "# Chalkboard\n",
    "# chalk_data_df   статистика по каждому игроку         - время, действие, игрок\n",
    "\n",
    "# Match report \n",
    "# match_summary   сильные и слабые стороны команд и просто отличительные черты стиля игры - длинное описание каждой\n",
    "# sit_report_data статитистика по видам атак, голам, пассам и нарушениям - Общие по матчу\n",
    "\n",
    "# Head2head\n",
    "# h2h_char_df     сильные и слабые стороны команд и просто отличительные черты стиля игры(до матча и больше статистики)\n",
    "# h2h_forecast_df и предсказания на основе сильных и слабых сторон\n",
    "\n",
    "finalURL = 'https://www.whoscored.com/Matches/1284753/Live/England-Premier-League-2018-2019-Cardiff-Newcastle-United'\n",
    "\n",
    "# Соединяемся с webdriver\n",
    "browser =  webdriver.Chrome()\n",
    "browser.set_window_size(1920, 1080) # По умолчанию 400X300 - может привести к проблемам\n",
    "browser.get(finalURL)\n",
    "\n",
    "sleep(1, 2)\n",
    "\n",
    "####################################################################################################################\n",
    "# Выгружаем статистику по странице match_center\n",
    "# Словарь атрибутов timeline\n",
    "timeline_attr_list = ['minute', 'second', 'team_id', 'player_id', 'assist', 'data_type', 'yellow_card',\n",
    "                      'second_yellow', 'red_card', 'card_type', 'penalty', 'penalty_miss', 'goal_own',\n",
    "                      'error_lead', 'shots_on_post', 'clear_line', 'tacklelastman', 'text']\n",
    "# Словарь основных и дополнительных элементов\n",
    "match_center_cat_table = {'passSuccess': ['passesAccurate'],\n",
    "                         # 'shotsTotal': [],\n",
    "                         'possession': [],\n",
    "                         'dribblesWon': [], # ['dribblesAttempted'],\n",
    "                         'aerialsWon': ['aerialSuccess', 'defensiveAerials'], # , 'offensiveAerials'\n",
    "                         'tackleSuccessful': ['tackleUnsuccesful'],\n",
    "                         'cornersTotal': ['cornerAccuracy'],\n",
    "                         'dispossessed': []}\n",
    "\n",
    "# Функция достает данные из match_center\n",
    "match_info, timeline_mc_df, main_stat_df, player_stats = get_match_center_data(browser, timeline_attr_list, match_center_cat_table)\n",
    "\n",
    "####################################################################################################################\n",
    "# Выгрузка данных из chalkboard\n",
    "# Атрибуты данных для timeline chalkboard\n",
    "chalk_timeline_attr_list = ['minute', 'second', 'team_id', 'player_id', 'data_type']\n",
    "# Словарь категорий данных для выгрузки из chalkboard\n",
    "chalk_cat_table = {'Shots': ['Shots on Target', 'Shots off Target', 'Woodworks', 'Blocked',\n",
    "                             'Penalty Area', 'Outside of box', 'Open Play', 'Fastbreak', 'Set Pieces'],\n",
    "                             #  '6-yard box','Penalty', 'Own Goal'],\n",
    "                   'Dribbles': ['Successful'],\n",
    "                   'Tackles Attempted': ['Successful Tackles'],\n",
    "                   'Interceptions': [],\n",
    "                   'Clearances': ['Total', 'Off The Line'], #, 'Head', 'Feet'],\n",
    "                   'Blocks': [], # ['Blocked Shots', 'Crosses'],  data_type 10 - Blocked Shots, 74 - Crosses \n",
    "                   'Offsides': [],\n",
    "                   'Fouls': [],\n",
    "                   'Aerial duels': [],\n",
    "                   'Touches': [],\n",
    "                   'Loss of possession': [], # ['Dispossessed', 'Turnover'], data_type 61 - Turnover, 50 - Dispossessed \n",
    "                   'Errors': [], # ['Lead to Shot', 'Lead to Goal'],\n",
    "                   'Saves': [],\n",
    "                   'Claims': [],\n",
    "                   'Punches': [],\n",
    "                   'Passes': ['Cross', 'Freekick', 'Corner', 'Through Ball', 'Throw In', 'Key Passes', \n",
    "                              'Long', 'Ground',  'Feet', 'Forward', 'Backward', 'Defensive Third', 'Mid Third']}\n",
    "                                #  'Short','Chipped','Head', 'Final Third','Left', 'Right',\n",
    "\n",
    "# Функция достает данные из chalkboard\n",
    "chalk_data_df = get_chalkboard_data(browser, chalk_cat_table, chalk_timeline_attr_list)\n",
    "\n",
    "####################################################################################################################\n",
    "# Выгрузка данных из match report\n",
    "# список с кнопками верхнего меню situational report(live_goals в конце,\n",
    "# чтобы потом переключать там меню и получить информацию из какой атаки пришли голы)\n",
    "css_list_sit_but = ['a[href=\"#live-passes\"]', 'a[href=\"#live-aggression\"]', 'a[href=\"#live-goals\"]']\n",
    "\n",
    "# В словаре собраны указатели на id таблицы с данными по каждому key-подразделу Situational report\n",
    "div_id_dict = {'attempts': ['live-goals-content-comparision', 'live-goals-info'],\n",
    "               'passes': ['live-passes-content-comparision', 'live-passes-info'],\n",
    "               'agression': ['live-aggression-content-comparision', 'live-aggression-info']}\n",
    "\n",
    "\n",
    "\n",
    "# Список с кнопками в situational report в Attempt types для выгрузки ситуаций из которой пришли голы\n",
    "xpath_attempt_type_list = ['Open Play', 'Set Piece', 'Counter Attack', 'Penalty', 'Own Goal']\n",
    "\n",
    "\n",
    "# Достаем картинки из positional report\n",
    "\n",
    "png_id_list = [{'stat_id': 'live-touch-channels',\n",
    "                 'stat_name': 'atack_sides', \n",
    "                 'home': 'live-touch-channels-content-homeStatsCanvas', \n",
    "                 'away': 'live-touch-channels-content-awayStatsCanvas'}, \n",
    "                {'stat_id': 'live-attempt-directions',\n",
    "                 'stat_name': 'attempt_dir',\n",
    "                 'home': 'live-attempt-directions-content-homeStatsCanvas',\n",
    "                 'away': 'live-attempt-directions-content-awayStatsCanvas'}, \n",
    "                {'stat_id': 'live-touch-zones',\n",
    "                 'stat_name': 'touch_zone',\n",
    "                 'home': 'live-touch-zones-contentStatsCanvas',\n",
    "                 'away': 'live-touch-zones-contentStatsCanvas'}, \n",
    "                {'stat_id': 'live-average-positions',\n",
    "                 'stat_name': 'average_pl_pos',\n",
    "                 'home': 'live-average-positions-content-homeStatsCanvas',\n",
    "                 'away': 'live-average-positions-content-awayStatsCanvas'}]\n",
    "\n",
    "# match_id для названия\n",
    "match_id = '1111'\n",
    "# путь от текущего для хранения фото\n",
    "png_dir = 'canvas_img'\n",
    "\n",
    "# функция достает данные из match_report\n",
    "sit_report_data, match_summary  = get_match_report_data(browser,  css_list_sit_but, div_id_dict, xpath_attempt_type_list,\n",
    "                                                        png_id_list, match_id, png_dir)\n",
    "\n",
    "####################################################################################################################\n",
    "# Выгрузка данных из head to head\n",
    "\n",
    "# для перехода по странице\n",
    "xpath_head_2_head = '//a[text()=\"Head to Head\"]'\n",
    "# функция достает данные со страницы head to head\n",
    "h2h_char_df, h2h_forecast_df = get_h2h_data(browser, xpath_head_2_head)\n",
    "\n",
    "# TODO Надо сделать обработку ошибок должным образом\n",
    "# Также посмотреть форматы данных.(Все в тексте)\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = main_stat_df.T[['cornerAccuracy', 'cornersTotal']].reset_index().rename({'index': 'side'}, axis='columns').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_func</th>\n",
       "      <th>lead_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>func</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>get_match_center_data</th>\n",
       "      <td>&lt;module&gt;</td>\n",
       "      <td>45.051883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get_chalkboard_data</th>\n",
       "      <td>&lt;module&gt;</td>\n",
       "      <td>149.444303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get_situational_report_data</th>\n",
       "      <td>get_match_report_data</td>\n",
       "      <td>14.574175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get_match_report_data</th>\n",
       "      <td>&lt;module&gt;</td>\n",
       "      <td>29.013620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get_h2h_data</th>\n",
       "      <td>&lt;module&gt;</td>\n",
       "      <td>7.946450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       parent_func   lead_time\n",
       "func                                                          \n",
       "get_match_center_data                     <module>   45.051883\n",
       "get_chalkboard_data                       <module>  149.444303\n",
       "get_situational_report_data  get_match_report_data   14.574175\n",
       "get_match_report_data                     <module>   29.013620\n",
       "get_h2h_data                              <module>    7.946450"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_df.rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-5bef0c250805>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0moracle_db\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'oracle://fevblp:fedosov13@orcl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moracle_db\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36mraw_connection\u001b[1;34m(self, _connection)\u001b[0m\n\u001b[0;32m   2186\u001b[0m         \"\"\"\n\u001b[0;32m   2187\u001b[0m         return self._wrap_pool_connect(\n\u001b[1;32m-> 2188\u001b[1;33m             self.pool.unique_connection, _connection)\n\u001b[0m\u001b[0;32m   2189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36m_wrap_pool_connect\u001b[1;34m(self, fn, connection)\u001b[0m\n\u001b[0;32m   2156\u001b[0m         \u001b[0mdialect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdialect\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2157\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2158\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2159\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mdialect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdbapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2160\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mconnection\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\pool.py\u001b[0m in \u001b[0;36munique_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \"\"\"\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_ConnectionFairy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_checkout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_create_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\pool.py\u001b[0m in \u001b[0;36m_checkout\u001b[1;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[0;32m    786\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_checkout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreadconns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfairy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfairy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 788\u001b[1;33m             \u001b[0mfairy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ConnectionRecord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m             \u001b[0mfairy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\pool.py\u001b[0m in \u001b[0;36mcheckout\u001b[1;34m(cls, pool)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheckout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m         \u001b[0mrec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mdbapi_connection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\pool.py\u001b[0m in \u001b[0;36m_do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1191\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msafe_reraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1193\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dec_overflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1194\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\util\\langhelpers.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exc_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m   \u001b[1;31m# remove potential circular references\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpy3k\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exc_info\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exc_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\util\\compat.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb, cause)\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\pool.py\u001b[0m in \u001b[0;36m_do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inc_overflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1190\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msafe_reraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\pool.py\u001b[0m in \u001b[0;36m_create_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[1;34m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_ConnectionRecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_invalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_checkin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\pool.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, pool, connect)\u001b[0m\n\u001b[0;32m    475\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__pool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_connect_check\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinalize_callback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeque\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\pool.py\u001b[0m in \u001b[0;36m__connect\u001b[1;34m(self, first_connect_check)\u001b[0m\n\u001b[0;32m    679\u001b[0m                 \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfirst_connect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m                     \u001b[0mfor_modify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m                     \u001b[0mexec_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m                 \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\event\\attr.py\u001b[0m in \u001b[0;36mexec_once\u001b[1;34m(self, *args, **kw)\u001b[0m\n\u001b[0;32m    272\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exec_once\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m                     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exec_once\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\event\\attr.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kw)\u001b[0m\n\u001b[0;32m    282\u001b[0m             \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlisteners\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m             \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\util\\langhelpers.py\u001b[0m in \u001b[0;36mgo\u001b[1;34m(*arg, **kw)\u001b[0m\n\u001b[0;32m   1332\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0monce\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m             \u001b[0monce_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0monce\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0monce_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\strategies.py\u001b[0m in \u001b[0;36mfirst_connect\u001b[1;34m(dbapi_connection, connection_record)\u001b[0m\n\u001b[0;32m    181\u001b[0m                                     _has_events=False)\n\u001b[0;32m    182\u001b[0m                 \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execution_options\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimmutabledict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m                 \u001b[0mdialect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m             \u001b[0mevent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlisten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'first_connect'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_connect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\dialects\\oracle\\cx_oracle.py\u001b[0m in \u001b[0;36minitialize\u001b[1;34m(self, connection)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 694\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOracleDialect_cx_oracle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    695\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_oracle_8\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupports_unicode_binds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\dialects\\oracle\\base.py\u001b[0m in \u001b[0;36minitialize\u001b[1;34m(self, connection)\u001b[0m\n\u001b[0;32m   1089\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1091\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOracleDialect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1092\u001b[0m         self.implicit_returning = self.__dict__.get(\n\u001b[0;32m   1093\u001b[0m             \u001b[1;34m'implicit_returning'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\default.py\u001b[0m in \u001b[0;36minitialize\u001b[1;34m(self, connection)\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_schema_name\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_default_schema_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_schema_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\dialects\\oracle\\base.py\u001b[0m in \u001b[0;36m_get_default_schema_name\u001b[1;34m(self, connection)\u001b[0m\n\u001b[0;32m   1177\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_default_schema_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m         return self.normalize_name(\n\u001b[1;32m-> 1179\u001b[1;33m             connection.execute('SELECT USER FROM DUAL').scalar())\n\u001b[0m\u001b[0;32m   1180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1181\u001b[0m     def _resolve_synonym(self, connection, desired_owner=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, object, *multiparams, **params)\u001b[0m\n\u001b[0;32m    940\u001b[0m         \"\"\"\n\u001b[0;32m    941\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute_on_connection\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36m_execute_text\u001b[1;34m(self, statement, multiparams, params)\u001b[0m\n\u001b[0;32m   1102\u001b[0m             \u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1104\u001b[1;33m             \u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1105\u001b[0m         )\n\u001b[0;32m   1106\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_events\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_events\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[0;32m   1198\u001b[0m                 \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1199\u001b[0m                 \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1200\u001b[1;33m                 context)\n\u001b[0m\u001b[0;32m   1201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_events\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_events\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[0;32m   1414\u001b[0m                 )\n\u001b[0;32m   1415\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1416\u001b[1;33m                 \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1418\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\util\\compat.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb, cause)\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[0;32m   1191\u001b[0m                         \u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m                         \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1193\u001b[1;33m                         context)\n\u001b[0m\u001b[0;32m   1194\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m             self._handle_dbapi_exception(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    505\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 507\u001b[1;33m         \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdo_execute_no_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "oracle_db = sa.create_engine('oracle://fevblp:fedosov13@orcl')\n",
    "connection = oracle_db.raw_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'OracleDialect_cx_oracle' object has no attribute 'default_schema_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-d6dc5b27c24b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'general_match_statistic'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moracle_db\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mif_exists\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'append'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SELECT * FROM general_match_statistic\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype)\u001b[0m\n\u001b[0;32m   2128\u001b[0m         sql.to_sql(self, name, con, schema=schema, if_exists=if_exists,\n\u001b[0;32m   2129\u001b[0m                    \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2130\u001b[1;33m                    dtype=dtype)\n\u001b[0m\u001b[0;32m   2131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2132\u001b[0m     def to_pickle(self, path, compression='infer',\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype)\u001b[0m\n\u001b[0;32m    448\u001b[0m     pandas_sql.to_sql(frame, name, if_exists=if_exists, index=index,\n\u001b[0;32m    449\u001b[0m                       \u001b[0mindex_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 450\u001b[1;33m                       chunksize=chunksize, dtype=dtype)\n\u001b[0m\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype)\u001b[0m\n\u001b[0;32m   1124\u001b[0m                          \u001b[0mif_exists\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mif_exists\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m                          schema=schema, dtype=dtype)\n\u001b[1;32m-> 1126\u001b[1;33m         \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1127\u001b[0m         \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mislower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mif_exists\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'fail'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Table '%s' already exists.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mexists\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpd_sql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhas_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msql_schema\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mhas_table\u001b[1;34m(self, name, schema)\u001b[0m\n\u001b[0;32m   1152\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnectable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdialect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhas_table\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m             \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m             \u001b[0mschema\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1155\u001b[0m         )\n\u001b[0;32m   1156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36mrun_callable\u001b[1;34m(self, callable_, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2054\u001b[0m         \"\"\"\n\u001b[0;32m   2055\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontextual_connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2056\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallable_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2057\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2058\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmultiparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36mrun_callable\u001b[1;34m(self, callable_, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1544\u001b[0m         \"\"\"\n\u001b[1;32m-> 1545\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1547\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_visitor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvisitorcallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\dialects\\oracle\\base.py\u001b[0m in \u001b[0;36mhas_table\u001b[1;34m(self, connection, table_name, schema)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhas_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtable_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1131\u001b[1;33m             \u001b[0mschema\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_schema_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1132\u001b[0m         cursor = connection.execute(\n\u001b[0;32m   1133\u001b[0m             sql.text(\"SELECT table_name FROM all_tables \"\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'OracleDialect_cx_oracle' object has no attribute 'default_schema_name'"
     ]
    }
   ],
   "source": [
    "df1.to_sql('general_match_statistic', con=connection, if_exists='append')\n",
    "connection.execute(\"SELECT * FROM general_match_statistic\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count_df = chalk_data_df.groupby(['minute', 'second', 'category', 'subcat']).count()\n",
    "# count_df.loc[count_df['data_type']==1]\n",
    "# # chalk_data_df.loc[(chalk_data_df['category']=='Passes')&(chalk_data_df['subcat'].isnull())]\n",
    "# # pd.Timestamp(chalk_data_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chalk_data_df.loc[chalk_data_df['category']=='Touches'].groupby('data_type').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chalk_data_df[(chalk_data_df['category']!='Touches')].fillna('main')\\\n",
    "#             .groupby(['data_type', 'category']).size().reset_index(name='freq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chalk_data_df.loc[(chalk_data_df['category']=='Touches') & (chalk_data_df['data_type']=='2')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chalk_data_df.loc[chalk_data_df['data_type'].isin(['2','42'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raj': ['e'], 'f': ['r']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = ['raj', 'e', 'f', 'r']\n",
    "a = {'raj': [], 'f': []}\n",
    "for ele in b:\n",
    "    if ele in ['raj', 'f']:\n",
    "        k = a[ele]\n",
    "    else:\n",
    "        k.append(ele)\n",
    "        # raise AssertionError\n",
    "        \n",
    "# a['raj'].append('aa')\n",
    "# a['raj'].append('a')\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
